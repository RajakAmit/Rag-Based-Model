ğŸ“„ RAG-based PDF Q&A System (LangGraph + OpenAI)

This project implements an advanced Retrieval-Augmented Generation (RAG) system using LangGraph, FAISS, and OpenAI GPT models. It allows to upload PDF documents (text + tables) and ask questions. The system extracts relevant chunks from PDFs, embeds them, retrieves context, and generates accurate, structured answers using LLMs.

ğŸš€ Features

Text & Table Extraction: Extracts text and tables row-by-row from PDFs using pdfplumber.

Embeddings: Uses OpenAIâ€™s text-embedding-3-small for vectorization.

Vector Store: FAISS for fast similarity search.

LLM Integration: OpenAI GPT models (gpt-4o-mini) for generation.

Workflow Orchestration: LangGraph for modular graph-based RAG (Embed â†’ Retrieve â†’ Generate).

Streamlit UI: Interactive web interface for PDF upload and question answering.

Multi-PDF Support: Handles multiple PDFs simultaneously.

ğŸ“‚ Project Structure
Rag_Model_ML/
â”‚â”€â”€ .env                    # OpenAI API Key
â”‚â”€â”€ app.py                  # Streamlit UI
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ extractor.py         # Extracts text & tables from PDFs
â”‚   â”œâ”€â”€ embedder.py          # Embeddings + FAISS index
â”‚   â”œâ”€â”€ retriever.py         # Retrieves top-k relevant chunks
â”‚   â”œâ”€â”€ graph_builder.py     # LangGraph workflow (Embed â†’ Retrieve â†’ Generate)
â”‚   â””â”€â”€ generator.py         # OpenAI GPT response generation
â”œâ”€â”€ data/                    # Uploaded PDF files
â””â”€â”€ requirements.txt

ğŸ”‘ Configuration

Create a .env file in the project root:

OPENAI_API_KEY=sk-your-real-api-key-here


âš ï¸ No quotes, no spaces.

ğŸ“ How It Works (Module Overview)
1ï¸âƒ£ Extractor (src/extractor.py)

Uses pdfplumber to extract:

Text from each page.

Tables row-by-row (converted to plain text with | separators).

Returns chunks: [Page 1] text, [Page 1 | Table 0] row1 | row2 | ....

2ï¸âƒ£ Embedder (src/embedder.py)

Embeds chunks using OpenAIEmbeddings (text-embedding-3-small).

Builds a FAISS index for similarity search.

Provides embedding for queries to retrieve relevant chunks.

3ï¸âƒ£ Retriever (src/retriever.py)

Performs top-k search on FAISS index.

Returns the most relevant chunks based on query embedding.

4ï¸âƒ£ Generator (src/generator.py)

Uses OpenAI GPT (gpt-4o-mini) via langchain_openai.ChatOpenAI.

Combines retrieved context + user query to generate:

Text answers: summarized in sentences.

Table answers: key rows/columns explained briefly.

If information is missing: responds "Not found in the provided document".

5ï¸âƒ£ LangGraph Workflow (src/graph_builder.py)

Defines a graph-based RAG pipeline:

Embed Node: Embeds user query.

Retrieve Node: Fetches top-k chunks from FAISS.

Generate Node: Calls GPT for final answer.

Modular and extensible for additional nodes/pipelines.

6ï¸âƒ£ Streamlit UI (app.py)

Allows uploading PDFs and asking questions.

Displays:

Answer generated by LLM.

Retrieved Context (expandable).

Automatically builds FAISS index and runs LangGraph workflow.

ğŸ§© Tech Stack
Component	Technology / Model
PDF Extraction	pdfplumber
Embeddings	OpenAI text-embedding-3-small
Vector Store	FAISS
LLM	OpenAI GPT gpt-4o-mini
Workflow	LangGraph (StateGraph)
Interface	Streamlit
Environment Config	.env (OpenAI API Key)
ğŸ”„ Workflow

Extract: Parse PDFs â†’ text + table chunks.

Embed: Convert chunks into vector embeddings.

Store: Save embeddings in FAISS.

Retrieve: Search top-k relevant chunks for query.

Generate: LLM generates structured answer using retrieved context.

UI: User sees answer + context in Streamlit app.

âœ… Running the App

From project root:

streamlit run app.py


Upload PDFs in .pdf format.

Type question in the input box.

Get AI-generated answers instantly.

Output Result
<img width="1812" height="877" alt="Screenshot 2025-08-26 204145" src="https://github.com/user-attachments/assets/310e1705-ea4b-441f-ba7c-134fe7e8d552" />
<img width="1832" height="861" alt="Screenshot 2025-08-26 204115" src="https://github.com/user-attachments/assets/755d831f-0de7-496f-bd0f-11bb1c490857" />


ğŸ›  Future Improvements

âœ… OCR support for scanned PDFs.

âœ… Table-aware embeddings for better accuracy.

âœ… Multi-modal RAG (text + images).

âœ… Optional Ollama local LLM support.

âœ… Advanced LangGraph multi-step reasoning pipelines.

ğŸ¤ Contributing

Fork â†’ branch â†’ feature â†’ PR.

Pull requests and suggestions are welcome!

ğŸ“œ License

MIT License
